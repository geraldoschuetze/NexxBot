import streamlit as st
import os
import openai
import uuid
import mimetypes
from pytube import YouTube
from pydub import AudioSegment
from langchain.chat_models import ChatOpenAI
from langchain.chains.question_answering import load_qa_chain
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Chave da OpenAI s
openai.api_key = os.getenv("OPENAI_API_KEY")
if not openai.api_key:
    st.error("OPENAI_API_KEY n√£o configurada.")
    st.stop()

# Configura layout do app
st.set_page_config(page_title="YouTube AI por √Åudio", layout="wide")
st.title("üéß YouTube AI ‚Äì Transcreve e responde perguntas")

# Entrada do usu√°rio
video_url = st.text_input("üîó URL do v√≠deo do YouTube:")
user_question = st.text_input("‚ùì Pergunta para a IA:")

MAX_MB = 24  # Limite do Whisper √© 25MB

# Fun√ß√£o para baixar e converter o √°udio
def baixar_audio_do_video(video_url):
    yt = YouTube(video_url)
    audio_stream = yt.streams.filter(only_audio=True).first()
    file_id = str(uuid.uuid4())
    temp_path = f"temp_{file_id}.mp4"
    audio_path = f"temp_{file_id}.mp3"
    audio_stream.download(filename=temp_path)

    # Convers√£o com qualidade e formato adequado
    audio = AudioSegment.from_file(temp_path)
    audio = audio.set_frame_rate(16000).set_channels(1)
    audio.export(audio_path, format="mp3", bitrate="192k")
    os.remove(temp_path)
    return audio_path

# Fun√ß√£o para transcrever e validar o arquivo
def transcrever_audio(audio_path):
    # Verificar tamanho
    tamanho = os.path.getsize(audio_path)
    if tamanho > MAX_MB * 1024 * 1024:
        raise RuntimeError("O arquivo ultrapassa 25MB permitido pelo Whisper da OpenAI.")

    # Verificar tipo MIME
    tipo, _ = mimetypes.guess_type(audio_path)
    if tipo not in ["audio/mpeg", "audio/mp3", "audio/wav", "audio/webm", "audio/mp4", "audio/x-m4a"]:
        raise RuntimeError(f"Tipo de √°udio inv√°lido para o Whisper: {tipo}")

    # Enviar para o Whisper
    with open(audio_path, "rb") as f:
        try:
            resultado = openai.Audio.transcribe("whisper-1", f)
            return resultado["text"]
        except Exception as e:
            raise RuntimeError(f"Erro ao transcrever com Whisper: {e}")

# Execu√ß√£o ao clicar no bot√£o
if st.button("üîç Analisar v√≠deo"):
    if not video_url or not user_question:
        st.warning("Preencha a URL do v√≠deo e a pergunta.")
        st.stop()

    with st.spinner("üéß Baixando e transcrevendo √°udio..."):
        try:
            audio_path = baixar_audio_do_video(video_url)
            transcricao = transcrever_audio(audio_path)
            os.remove(audio_path)
        except Exception as e:
            st.error(f"Erro ao processar o √°udio: {e}")
            st.stop()

    with st.spinner("ü§ñ Enviando para ChatGPT..."):
        llm = ChatOpenAI(
            temperature=0.3,
            model_name="gpt-3.5-turbo",
            openai_api_key=openai.api_key,
        )
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        docs = text_splitter.create_documents([transcricao])

        qa_chain = load_qa_chain(llm, chain_type="stuff")
        resposta = qa_chain.run(input_documents=docs, question=user_question)

    st.success("‚úÖ Resposta gerada com sucesso!")
    st.markdown(f"**Pergunta:** {user_question}")
    st.markdown(f"**Resposta:** {resposta}")
